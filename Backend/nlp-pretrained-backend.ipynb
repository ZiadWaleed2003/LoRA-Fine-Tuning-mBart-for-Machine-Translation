{"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.11"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[],"dockerImageVersionId":31011,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# Installs\n!pip install flask pyngrok\n\n# Imports\nfrom flask import Flask, request, jsonify\nfrom pyngrok import ngrok\nimport torch  # Or the framework your model uses\nimport os\nimport time\nimport json\nimport regex as re\nfrom transformers import AutoTokenizer, AutoModelForSeq2SeqLM\nfrom peft import PeftModel, PeftConfig\n\n\n# I dunno if kaggle has an .env\nngrok.set_auth_token('2wjAHHT3hF4pB8QYXfCMy5cNMyJ_7qBbJPRrWxswuCcsz4Fjg')","metadata":{"execution":{"iopub.status.busy":"2025-05-06T18:32:01.302373Z","iopub.execute_input":"2025-05-06T18:32:01.303064Z","iopub.status.idle":"2025-05-06T18:32:48.161793Z","shell.execute_reply.started":"2025-05-06T18:32:01.303039Z","shell.execute_reply":"2025-05-06T18:32:48.161137Z"},"trusted":true},"outputs":[{"name":"stdout","text":"Requirement already satisfied: flask in /usr/local/lib/python3.11/dist-packages (3.1.0)\nCollecting pyngrok\n  Downloading pyngrok-7.2.7-py3-none-any.whl.metadata (9.4 kB)\nRequirement already satisfied: Werkzeug>=3.1 in /usr/local/lib/python3.11/dist-packages (from flask) (3.1.3)\nRequirement already satisfied: Jinja2>=3.1.2 in /usr/local/lib/python3.11/dist-packages (from flask) (3.1.6)\nRequirement already satisfied: itsdangerous>=2.2 in /usr/local/lib/python3.11/dist-packages (from flask) (2.2.0)\nRequirement already satisfied: click>=8.1.3 in /usr/local/lib/python3.11/dist-packages (from flask) (8.1.8)\nRequirement already satisfied: blinker>=1.9 in /usr/local/lib/python3.11/dist-packages (from flask) (1.9.0)\nRequirement already satisfied: PyYAML>=5.1 in /usr/local/lib/python3.11/dist-packages (from pyngrok) (6.0.2)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from Jinja2>=3.1.2->flask) (3.0.2)\nDownloading pyngrok-7.2.7-py3-none-any.whl (23 kB)\nInstalling collected packages: pyngrok\nSuccessfully installed pyngrok-7.2.7\n","output_type":"stream"},{"name":"stderr","text":"2025-05-06 18:32:30.079488: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1746556350.531790      31 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1746556350.670013      31 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"},{"name":"stdout","text":"                                                                                                    \r","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"def clean_arabic(text):\n    # Remove newlines\n    text = re.sub(r'\\\\n|\\n', ' ', text)\n\n    # Normalize 'أ', 'إ', 'آ' -> 'ا'\n    text = re.sub(r'[أإآ]', 'ا', text)\n\n    # Normalize 'ة' -> 'ه'\n    text = re.sub(r'[ة]', 'ه', text)\n\n    # Normalize Eastern Arabic numerals to Western Arabic numerals\n    arabic_numerals = '٠١٢٣٤٥٦٧٨٩'\n    western_numerals = '0123456789'\n    trans = str.maketrans(arabic_numerals, western_numerals)\n    text = text.translate(trans)\n\n    # Remove diacritics (tashkeel)\n    text = re.sub(r'[\\u064B-\\u065F]', '', text)\n\n    # Remove tatweel\n    text = re.sub(r'\\u0640', '', text)\n\n    # Remove Arabic and Western punctuation\n    text = re.sub(r'[،؛«»,!?()\\[\\]{}\"\\'\\\\]', '', text)\n\n    # Remove multiple spaces\n    text = re.sub(r'\\s+', ' ', text)\n\n    return text.strip()\n\n# Example usage\nexample_text = \"أهلًا وسهلًا! كيف حالك؟\"\ncleaned_text = clean_arabic(example_text)\nprint(cleaned_text)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-06T18:32:48.163115Z","iopub.execute_input":"2025-05-06T18:32:48.163781Z","iopub.status.idle":"2025-05-06T18:32:48.171420Z","shell.execute_reply.started":"2025-05-06T18:32:48.163750Z","shell.execute_reply":"2025-05-06T18:32:48.170816Z"}},"outputs":[{"name":"stdout","text":"اهلا وسهلا كيف حالك؟\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\nfrom peft import PeftModel, PeftConfig\n\n# Load tokenizer\ntokenizer = AutoTokenizer.from_pretrained(\"ZiadWaleed/mBart-LoRA-for-MT-ar-en2\")\n\n# Load PEFT config to get base model name\nconfig = PeftConfig.from_pretrained(\"ZiadWaleed/mBart-LoRA-for-MT-ar-en2\")\nbase_model = AutoModelForSeq2SeqLM.from_pretrained(config.base_model_name_or_path)\n\n# Load LoRA adapter on top of base model\nmodel = PeftModel.from_pretrained(base_model, \"ZiadWaleed/mBart-LoRA-for-MT-ar-en2\")\n\n\n# Set model to evaluation mode\nmodel.eval()\n\n# Set up for translation\nSRC_LANG = \"ar_AR\"\nTGT_LANG = \"en_XX\"\n\ntokenizer.src_lang = SRC_LANG\ntokenizer.tgt_lang = TGT_LANG\n\n# Set forced BOS token to the target language\nmodel.config.forced_bos_token_id = tokenizer.lang_code_to_id[TGT_LANG]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-06T18:32:48.172338Z","iopub.execute_input":"2025-05-06T18:32:48.172645Z","iopub.status.idle":"2025-05-06T18:33:02.253000Z","shell.execute_reply.started":"2025-05-06T18:32:48.172619Z","shell.execute_reply":"2025-05-06T18:33:02.252206Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/11.0k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d5d0a86c205949f0aba45255b9f92fe6"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"sentencepiece.bpe.model:   0%|          | 0.00/5.07M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"02479bdd1c604ae782dfd980d2c86549"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/17.1M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3b967f86ae314549a6a09b5372cd92b7"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/992 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6f127a3237b44960844177fa2f41f7ff"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"adapter_config.json:   0%|          | 0.00/813 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d35fc16df18e4beaa300324bdb4e4e94"}},"metadata":{}},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/peft/config.py:162: UserWarning: Unexpected keyword arguments ['alpha_pattern', 'bias', 'corda_config', 'eva_config', 'exclude_modules', 'fan_in_fan_out', 'init_lora_weights', 'layer_replication', 'layers_pattern', 'layers_to_transform', 'loftq_config', 'lora_alpha', 'lora_bias', 'lora_dropout', 'megatron_config', 'megatron_core', 'modules_to_save', 'r', 'rank_pattern', 'target_modules', 'trainable_token_indices', 'use_dora', 'use_rslora'] for class PeftConfig, these are ignored. This probably means that you're loading a configuration file that was saved using a higher version of the library and additional parameters have been introduced since. It is highly recommended to upgrade the PEFT version before continuing (e.g. by running `pip install -U peft`).\n  warnings.warn(\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/1.43k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"23d3629eb00a469f80752f15e985d5fd"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/2.44G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"88c73e317bd8422599c33a3f4c37350c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"generation_config.json:   0%|          | 0.00/261 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1d53e0316ac94c638ab8b396a972ce1f"}},"metadata":{}},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/peft/config.py:162: UserWarning: Unexpected keyword arguments ['corda_config', 'trainable_token_indices'] for class LoraConfig, these are ignored. This probably means that you're loading a configuration file that was saved using a higher version of the library and additional parameters have been introduced since. It is highly recommended to upgrade the PEFT version before continuing (e.g. by running `pip install -U peft`).\n  warnings.warn(\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"adapter_model.safetensors:   0%|          | 0.00/14.2M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d41814449da84f8a8755b38eb81ec60b"}},"metadata":{}}],"execution_count":3},{"cell_type":"code","source":"def translate(arabic_text , model):\n\n    device = torch.device(\"cpu\")\n    model = model.to(device)\n    arabic_text = clean_arabic(arabic_text)\n    inputs = tokenizer(arabic_text, return_tensors=\"pt\", padding=True, truncation=True)\n    inputs = {k: v.to(\"cpu\") for k, v in inputs.items()}  # Ensure on CPU\n\n    model.eval()\n    with torch.no_grad():\n        translated_tokens = model.generate(\n            input_ids=inputs[\"input_ids\"],\n            attention_mask=inputs[\"attention_mask\"],\n            max_length=128,\n            num_beams=5,\n            early_stopping=True,\n        )\n\n    translated_text = tokenizer.batch_decode(translated_tokens, skip_special_tokens=True)[0]\n    return translated_text\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-06T18:33:02.254307Z","iopub.execute_input":"2025-05-06T18:33:02.254638Z","iopub.status.idle":"2025-05-06T18:33:02.259690Z","shell.execute_reply.started":"2025-05-06T18:33:02.254620Z","shell.execute_reply":"2025-05-06T18:33:02.258928Z"}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"app = Flask(__name__)\n\n@app.route('/api/predict', methods=['POST'])\ndef predict():\n    \"\"\"\n    Expects JSON with 'text' field\n    \"\"\"\n    data = request.json\n    \n    if not data or 'text' not in data:\n        return jsonify({\n            'error': 'Missing required field: text'\n        }), 400\n    \n    if re.fullmatch('^[A-Za-z]+$', data['text']):\n        return jsonify({\n            'error': \"Invalid Language - English text detected\"\n        }), 400\n\n    text = clean_arabic(data['text'])\n    \n    try:\n        result = translate(text, model);\n        return jsonify(result)\n    \n    except Exception as e:\n        return jsonify({\n            'error': str(e)\n        }), 500\n\n@app.route('/api/status', methods=['GET'])\ndef status():\n    return jsonify({\n        'status': 'up',\n        'model': 'loaded',\n        'timestamp': time.strftime(\"%Y-%m-%d %H:%M:%S\")\n    })\n\n@app.after_request\ndef after_request(response):\n    response.headers.add('Access-Control-Allow-Origin', '*')\n    response.headers.add('Access-Control-Allow-Headers', 'Content-Type,Authorization')\n    response.headers.add('Access-Control-Allow-Methods', 'GET,POST,OPTIONS')\n    return response","metadata":{"execution":{"iopub.status.busy":"2025-05-06T18:33:02.260423Z","iopub.execute_input":"2025-05-06T18:33:02.261199Z","iopub.status.idle":"2025-05-06T18:33:02.282141Z","shell.execute_reply.started":"2025-05-06T18:33:02.261176Z","shell.execute_reply":"2025-05-06T18:33:02.281538Z"},"trusted":true},"outputs":[],"execution_count":5},{"cell_type":"code","source":"def start_server():\n    port = 5000\n    public_url = ngrok.connect(port).public_url\n    print(f\" * Ngrok tunnel \\\"{public_url}\\\" -> \\\"http://127.0.0.1:{port}\\\"\")\n    print(f\" * API endpoint: {public_url}/api/predict\")\n    app.run(host='0.0.0.0', port=port)\n\nif __name__ == '__main__':\n    start_server()\n","metadata":{"execution":{"iopub.status.busy":"2025-05-06T18:33:02.282810Z","iopub.execute_input":"2025-05-06T18:33:02.283051Z"},"trusted":true},"outputs":[{"name":"stdout","text":" * Ngrok tunnel \"https://ca46-34-28-237-149.ngrok-free.app\" -> \"http://127.0.0.1:5000\"\n * API endpoint: https://ca46-34-28-237-149.ngrok-free.app/api/predict\n * Serving Flask app '__main__'\n * Debug mode: off\n","output_type":"stream"},{"name":"stderr","text":"Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n/usr/local/lib/python3.11/dist-packages/transformers/generation/utils.py:1666: UserWarning: You have modified the pretrained model configuration to control generation. This is a deprecated strategy to control generation and will be removed in v5. Please use and modify the model generation configuration (see https://huggingface.co/docs/transformers/generation_strategies#default-text-generation-configuration )\n  warnings.warn(\n","output_type":"stream"}],"execution_count":null}]}