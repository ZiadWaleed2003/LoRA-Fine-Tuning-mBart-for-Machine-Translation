{"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.11"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[],"dockerImageVersionId":31011,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# Installs\n!pip install flask pyngrok\n\n# Imports\nfrom flask import Flask, request, jsonify\nfrom pyngrok import ngrok\nimport torch  # Or the framework your model uses\nimport os\nimport time\nimport json\nimport regex as re\nfrom transformers import AutoTokenizer, AutoModelForSeq2SeqLM\nfrom peft import PeftModel, PeftConfig\n\n\n# I dunno if kaggle has an .env\nngrok.set_auth_token('2wjAHHT3hF4pB8QYXfCMy5cNMyJ_7qBbJPRrWxswuCcsz4Fjg')","metadata":{"execution":{"iopub.status.busy":"2025-05-06T18:51:29.648621Z","iopub.execute_input":"2025-05-06T18:51:29.648810Z","iopub.status.idle":"2025-05-06T18:52:03.527354Z","shell.execute_reply.started":"2025-05-06T18:51:29.648792Z","shell.execute_reply":"2025-05-06T18:52:03.526686Z"},"trusted":true},"outputs":[{"name":"stdout","text":"Requirement already satisfied: flask in /usr/local/lib/python3.11/dist-packages (3.1.0)\nCollecting pyngrok\n  Downloading pyngrok-7.2.7-py3-none-any.whl.metadata (9.4 kB)\nRequirement already satisfied: Werkzeug>=3.1 in /usr/local/lib/python3.11/dist-packages (from flask) (3.1.3)\nRequirement already satisfied: Jinja2>=3.1.2 in /usr/local/lib/python3.11/dist-packages (from flask) (3.1.6)\nRequirement already satisfied: itsdangerous>=2.2 in /usr/local/lib/python3.11/dist-packages (from flask) (2.2.0)\nRequirement already satisfied: click>=8.1.3 in /usr/local/lib/python3.11/dist-packages (from flask) (8.1.8)\nRequirement already satisfied: blinker>=1.9 in /usr/local/lib/python3.11/dist-packages (from flask) (1.9.0)\nRequirement already satisfied: PyYAML>=5.1 in /usr/local/lib/python3.11/dist-packages (from pyngrok) (6.0.2)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from Jinja2>=3.1.2->flask) (3.0.2)\nDownloading pyngrok-7.2.7-py3-none-any.whl (23 kB)\nInstalling collected packages: pyngrok\nSuccessfully installed pyngrok-7.2.7\n","output_type":"stream"},{"name":"stderr","text":"2025-05-06 18:51:49.541895: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1746557509.777100      31 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1746557509.847685      31 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"},{"name":"stdout","text":"                                                                                                    \r","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"def clean_arabic(text):\n    # Remove newlines\n    text = re.sub(r'\\\\n|\\n', ' ', text)\n\n    # Normalize 'أ', 'إ', 'آ' -> 'ا'\n    text = re.sub(r'[أإآ]', 'ا', text)\n\n    # Normalize 'ة' -> 'ه'\n    text = re.sub(r'[ة]', 'ه', text)\n\n    # Normalize Eastern Arabic numerals to Western Arabic numerals\n    arabic_numerals = '٠١٢٣٤٥٦٧٨٩'\n    western_numerals = '0123456789'\n    trans = str.maketrans(arabic_numerals, western_numerals)\n    text = text.translate(trans)\n\n    # Remove diacritics (tashkeel)\n    text = re.sub(r'[\\u064B-\\u065F]', '', text)\n\n    # Remove tatweel\n    text = re.sub(r'\\u0640', '', text)\n\n    # Remove Arabic and Western punctuation\n    text = re.sub(r'[،؛«»,!?()\\[\\]{}\"\\'\\\\]', '', text)\n\n    # Remove multiple spaces\n    text = re.sub(r'\\s+', ' ', text)\n\n    return text.strip()\n\n# Example usage\nexample_text = \"أهلًا وسهلًا! كيف حالك؟\"\ncleaned_text = clean_arabic(example_text)\nprint(cleaned_text)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-06T18:52:03.528591Z","iopub.execute_input":"2025-05-06T18:52:03.529060Z","iopub.status.idle":"2025-05-06T18:52:03.537228Z","shell.execute_reply.started":"2025-05-06T18:52:03.529040Z","shell.execute_reply":"2025-05-06T18:52:03.536493Z"}},"outputs":[{"name":"stdout","text":"اهلا وسهلا كيف حالك؟\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\nfrom peft import PeftModel, PeftConfig\n\n# Load tokenizer\ntokenizer = AutoTokenizer.from_pretrained(\"ZiadWaleed/mBart-LoRA-for-MT-ar-en2\")\n\n# Load PEFT config to get base model name\nconfig = PeftConfig.from_pretrained(\"ZiadWaleed/mBart-LoRA-for-MT-ar-en2\")\nbase_model = AutoModelForSeq2SeqLM.from_pretrained(config.base_model_name_or_path)\n\n# Load LoRA adapter on top of base model\nmodel = PeftModel.from_pretrained(base_model, \"ZiadWaleed/mBart-LoRA-for-MT-ar-en2\")\n\n\n# Set model to evaluation mode\nmodel.eval()\n\n# Set up for translation\nSRC_LANG = \"ar_AR\"\nTGT_LANG = \"en_XX\"\n\ntokenizer.src_lang = SRC_LANG\ntokenizer.tgt_lang = TGT_LANG\n\n# Set forced BOS token to the target language\nmodel.config.forced_bos_token_id = tokenizer.lang_code_to_id[TGT_LANG]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-06T18:52:03.537923Z","iopub.execute_input":"2025-05-06T18:52:03.538179Z","iopub.status.idle":"2025-05-06T18:52:17.020337Z","shell.execute_reply.started":"2025-05-06T18:52:03.538158Z","shell.execute_reply":"2025-05-06T18:52:17.019528Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/11.0k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c63a0c90756a421fb9c2e137a59ac7f3"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"sentencepiece.bpe.model:   0%|          | 0.00/5.07M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7adf8e617d1d4052b1dc1a413d8e15b8"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/17.1M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"37e9c44d274941c4810e112c8df76dbd"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/992 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"decb9a533aa0441dbf6efaddb64d6429"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"adapter_config.json:   0%|          | 0.00/813 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7b80bb691115495c8e2e9103422adbe5"}},"metadata":{}},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/peft/config.py:162: UserWarning: Unexpected keyword arguments ['alpha_pattern', 'bias', 'corda_config', 'eva_config', 'exclude_modules', 'fan_in_fan_out', 'init_lora_weights', 'layer_replication', 'layers_pattern', 'layers_to_transform', 'loftq_config', 'lora_alpha', 'lora_bias', 'lora_dropout', 'megatron_config', 'megatron_core', 'modules_to_save', 'r', 'rank_pattern', 'target_modules', 'trainable_token_indices', 'use_dora', 'use_rslora'] for class PeftConfig, these are ignored. This probably means that you're loading a configuration file that was saved using a higher version of the library and additional parameters have been introduced since. It is highly recommended to upgrade the PEFT version before continuing (e.g. by running `pip install -U peft`).\n  warnings.warn(\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/1.43k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"78f09d644ad04452bb6e941eb12752bb"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/2.44G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3e6b1190ade743d2959701c33dba3270"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"generation_config.json:   0%|          | 0.00/261 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"56b71baa4e3946989e9c86816ca49d3c"}},"metadata":{}},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/peft/config.py:162: UserWarning: Unexpected keyword arguments ['corda_config', 'trainable_token_indices'] for class LoraConfig, these are ignored. This probably means that you're loading a configuration file that was saved using a higher version of the library and additional parameters have been introduced since. It is highly recommended to upgrade the PEFT version before continuing (e.g. by running `pip install -U peft`).\n  warnings.warn(\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"adapter_model.safetensors:   0%|          | 0.00/14.2M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5d86f89d326b4fa88aa4b4af82728eb0"}},"metadata":{}}],"execution_count":3},{"cell_type":"code","source":"def translate(arabic_text , model):\n\n    device = torch.device(\"cuda\")\n    model = model.to(device)\n    arabic_text = clean_arabic(arabic_text)\n    inputs = tokenizer(arabic_text, return_tensors=\"pt\", padding=True, truncation=True)\n    inputs = {k: v.to(\"cuda\") for k, v in inputs.items()}  # Ensure on CPU\n\n    model.eval()\n    with torch.no_grad():\n        translated_tokens = model.generate(\n            input_ids=inputs[\"input_ids\"],\n            attention_mask=inputs[\"attention_mask\"],\n            max_length=128,\n            num_beams=5,\n            early_stopping=True,\n        )\n\n    translated_text = tokenizer.batch_decode(translated_tokens, skip_special_tokens=True)[0]\n    return translated_text\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-06T18:52:17.021792Z","iopub.execute_input":"2025-05-06T18:52:17.021992Z","iopub.status.idle":"2025-05-06T18:52:17.027126Z","shell.execute_reply.started":"2025-05-06T18:52:17.021975Z","shell.execute_reply":"2025-05-06T18:52:17.026337Z"}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"app = Flask(__name__)\n\n@app.route('/api/predict', methods=['POST'])\ndef predict():\n    \"\"\"\n    Expects JSON with 'text' field\n    \"\"\"\n    data = request.json\n    \n    if not data or 'text' not in data:\n        return jsonify({\n            'error': 'Missing required field: text'\n        }), 400\n    \n    if re.fullmatch('^[A-Za-z]+$', data['text']):\n        return jsonify({\n            'error': \"Invalid Language - English text detected\"\n        }), 400\n\n    text = clean_arabic(data['text'])\n    \n    try:\n        result = translate(text, model);\n        return jsonify(result)\n    \n    except Exception as e:\n        return jsonify({\n            'error': str(e)\n        }), 500\n\n@app.route('/api/status', methods=['GET'])\ndef status():\n    return jsonify({\n        'status': 'up',\n        'model': 'loaded',\n        'timestamp': time.strftime(\"%Y-%m-%d %H:%M:%S\")\n    })\n\n@app.after_request\ndef after_request(response):\n    response.headers.add('Access-Control-Allow-Origin', '*')\n    response.headers.add('Access-Control-Allow-Headers', 'Content-Type,Authorization')\n    response.headers.add('Access-Control-Allow-Methods', 'GET,POST,OPTIONS')\n    return response","metadata":{"execution":{"iopub.status.busy":"2025-05-06T18:52:17.027766Z","iopub.execute_input":"2025-05-06T18:52:17.027954Z","iopub.status.idle":"2025-05-06T18:52:17.044949Z","shell.execute_reply.started":"2025-05-06T18:52:17.027940Z","shell.execute_reply":"2025-05-06T18:52:17.044331Z"},"trusted":true},"outputs":[],"execution_count":5},{"cell_type":"code","source":"def start_server():\n    port = 5000\n    public_url = ngrok.connect(port).public_url\n    print(f\" * Ngrok tunnel \\\"{public_url}\\\" -> \\\"http://127.0.0.1:{port}\\\"\")\n    print(f\" * API endpoint: {public_url}/api/predict\")\n    app.run(host='0.0.0.0', port=port)\n\nif __name__ == '__main__':\n    start_server()\n","metadata":{"execution":{"iopub.status.busy":"2025-05-06T18:52:17.045615Z","iopub.execute_input":"2025-05-06T18:52:17.045839Z","execution_failed":"2025-05-06T19:02:20.281Z"},"trusted":true},"outputs":[{"name":"stdout","text":" * Ngrok tunnel \"https://65aa-34-82-165-170.ngrok-free.app\" -> \"http://127.0.0.1:5000\"\n * API endpoint: https://65aa-34-82-165-170.ngrok-free.app/api/predict\n * Serving Flask app '__main__'\n * Debug mode: off\n","output_type":"stream"},{"name":"stderr","text":"Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n/usr/local/lib/python3.11/dist-packages/transformers/generation/utils.py:1666: UserWarning: You have modified the pretrained model configuration to control generation. This is a deprecated strategy to control generation and will be removed in v5. Please use and modify the model generation configuration (see https://huggingface.co/docs/transformers/generation_strategies#default-text-generation-configuration )\n  warnings.warn(\n","output_type":"stream"}],"execution_count":null}]}